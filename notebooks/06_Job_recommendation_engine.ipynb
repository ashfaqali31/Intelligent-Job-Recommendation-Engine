{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d7223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d229d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths & setup\n",
    "resume_skil_features_path = 'C:/Users/ashua/Desktop/Inelligent Job Recomendation Engine/data/Feature Engineering Data/resume_skill_features.csv'\n",
    "job_skil_features_path = 'C:/Users/ashua/Desktop/Inelligent Job Recomendation Engine/data/Feature Engineering Data/job_skill_features.csv'\n",
    "training_data_path = 'C:/Users/ashua/Desktop/Inelligent Job Recomendation Engine/data/Supervised Training/supervised_training_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a9a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models we need to retrain to get the final model object\n",
    "# In a production environment, these would be loaded from a saved pickle/joblib file.\n",
    "# Here, we quickly retrain them using the same logic as the previous script to get the object.\n",
    "\n",
    "def get_trained_model(X, y):\n",
    "    print(\"Retraining the final Random Forest Model (best Performer) for deployment...\")\n",
    "\n",
    "    # Split data again to ensure consistent feature scaling/ordering\n",
    "    X_train, _, y_train, _ = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    #train the best model (Random Forest Classifier)\n",
    "    rf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    return rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cab89bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Final Job Recommendation Engine ---\n"
     ]
    }
   ],
   "source": [
    "# Load the data and retrain the model\n",
    "print(\"--- Starting Final Job Recommendation Engine ---\")\n",
    "\n",
    "try:\n",
    "    #Load the data\n",
    "    training_data = pd.read_csv(training_data_path)\n",
    "    resume_features_df = pd.read_csv(resume_skil_features_path).set_index('ID')\n",
    "    job_features_df = pd.read_csv(job_skil_features_path).set_index('job_id')\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Missing required data file. Please ensure '{e.filename}' is available.\")\n",
    "    exit()\n",
    "    \n",
    "except KeyError as e:\n",
    "    # Catch errors if 'ID' or 'job_id' columns are missing in feature files\n",
    "    print(f\"Error: Missing required index column {e} in one of the feature files. Check Phase 2 output files.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0017b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining the final Random Forest Model (best Performer) for deployment...\n",
      "Final model ready for deployment.\n"
     ]
    }
   ],
   "source": [
    "# Extract feature columns based on what was used in training\n",
    "feature_columns = [c for c in training_data.columns if c.startswith('R_') or c.startswith('J_')]\n",
    "\n",
    "# Ensure we only use the identified feature columns from the training data\n",
    "X_train_full = training_data[feature_columns]\n",
    "y_train_full = training_data['label']\n",
    "\n",
    "# Extract the base skill columns to reconstruct the feature list later\n",
    "skill_cols_base = [c.replace('R_', '') for c in feature_columns if c.startswith('R_')]\n",
    "resume_skill_cols = [f'R_{c}' for c in skill_cols_base]\n",
    "job_skill_cols = [f'J_{c}' for c in skill_cols_base]\n",
    "all_feature_cols = resume_skill_cols + job_skill_cols   \n",
    "\n",
    "#Retrain the model to get the deployable object\n",
    "final_model = get_trained_model(X_train_full, y_train_full)\n",
    "print(\"Final model ready for deployment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e154a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation function\n",
    "def generate_recommendations(resume_id, job_ids, final_model, resume_features, job_features, feature_cols):\n",
    "\n",
    "    print(f\"\\n2.1. Generating recommendations for Resume ID: {resume_id} against {len(job_ids)} jobs...\")\n",
    "    if resume_id not in resume_features.index:\n",
    "        print(f\"Error: Resume ID {resume_id} not found in features data.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # check if the target resume exists\n",
    "    R_vec = resume_features.loc[resume_id].values\n",
    "\n",
    "    #2 Extrat job features vectors\n",
    "    job_ids_valid = [j_id for j_id in job_ids if j_id in job_features.index]\n",
    "\n",
    "    if not job_ids_valid:\n",
    "        print(\"Warning: None of the provided job IDs were found in the job features data.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    J_matrix = job_features.loc[job_ids_valid].values\n",
    "\n",
    "    # create the input matrix (X_preditor)\n",
    "    # The input needs to be N rows (number of jobs) x 70 columns (35 R features + 35 J features)\n",
    "\n",
    "    #Title the resume vector (R_vec) to match the number of jobs\n",
    "    R_matrix_tiled = np.tile(R_vec, (len(job_ids_valid), 1))\n",
    "\n",
    "    #concatinate the tiled R_matrix with the J_matrix horizontally\n",
    "    # R_features (35 cols) followed by J_features (35 cols)\n",
    "    X_predit = np.hstack((R_matrix_tiled, J_matrix))\n",
    "\n",
    "    # predict the match probabilities\n",
    "    # we only need the probability of the positive class (match = 1)\n",
    "    match_probalities = final_model.predict_proba(X_predit)[:, 1]\n",
    "\n",
    "    # Compilte the results into a DataFrame\n",
    "    recommendations_df = pd.DataFrame({\n",
    "        'job_id': job_ids_valid,\n",
    "        'predicted_score': match_probalities\n",
    "    })\n",
    "\n",
    "    # Rank and format the results\n",
    "    recommendations_df = recommendations_df.sort_values(by='predicted_score', ascending=False).reset_index(drop=True)\n",
    "    recommendations_df['rank'] = recommendations_df.index + 1\n",
    "\n",
    "    return recommendations_df[['rank', 'job_id', 'predicted_score']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c341f2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.1. Generating recommendations for Resume ID: 16852973 against 10 jobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run Recommendation Example (Use a sample from our data)\n",
    "\n",
    "SAMPLE_RESUME_ID = resume_features_df.index[0]  # Use the first resume ID found\n",
    "SAMPLE_JOB_IDS = job_features_df.index[5:15].tolist() # Use the next 10 job IDs\n",
    "\n",
    "# Run the engine\n",
    "recommendations = generate_recommendations(\n",
    "    resume_id=SAMPLE_RESUME_ID,\n",
    "    job_ids=SAMPLE_JOB_IDS,\n",
    "    final_model=final_model,\n",
    "    resume_features=resume_features_df,\n",
    "    job_features=job_features_df,\n",
    "    feature_cols=all_feature_cols\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8849ec1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FINAL JOB RECOMMENDATION LIST ---\n",
      "Target Resume: 16852973\n",
      "|    rank |         job_id |   predicted_score |\n",
      "|--------:|---------------:|------------------:|\n",
      "|  1.0000 |  35982263.0000 |            0.2029 |\n",
      "|  2.0000 |  56924323.0000 |            0.1628 |\n",
      "|  3.0000 |  83789755.0000 |            0.1353 |\n",
      "|  4.0000 |  23221523.0000 |            0.1353 |\n",
      "|  5.0000 |  91700727.0000 |            0.1180 |\n",
      "|  6.0000 |  11009123.0000 |            0.1039 |\n",
      "|  7.0000 | 103254301.0000 |            0.1039 |\n",
      "|  8.0000 |  95428182.0000 |            0.0930 |\n",
      "|  9.0000 | 111513530.0000 |            0.0797 |\n",
      "| 10.0000 |  69333422.0000 |            0.0481 |\n",
      "\n",
      "Recommendation Complete.\n"
     ]
    }
   ],
   "source": [
    "#Final Output\n",
    "if not recommendations.empty:\n",
    "    print(\"--- FINAL JOB RECOMMENDATION LIST ---\")\n",
    "    print(f\"Target Resume: {SAMPLE_RESUME_ID}\")\n",
    "    print(recommendations.to_markdown(index=False, floatfmt=\".4f\"))\n",
    "    print(\"\\nRecommendation Complete.\")\n",
    "else:\n",
    "    print(\"\\nRecommendation failed or returned an empty set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461fa36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
